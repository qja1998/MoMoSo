{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gemini 텍스트 생성\n",
    "\n",
    "* 모델 종류: https://ai.google.dev/gemini-api/docs/models/gemini?hl=ko&_gl=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# 환경변수 로드 및 GEMINI_API_KEY 가져오기\n",
    "load_dotenv()\n",
    "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 텍스트 전용 입력에서 텍스트 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "\n",
    "client = genai.Client(api_key=\"GEMINI_API_KEY\")\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    contents=[\"How does AI work?\"])\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 텍스트 및 이미지 입력에서 텍스트 생성\n",
    "\n",
    "* Gemini API는 텍스트와 미디어 파일을 결합한 멀티모달 입력을 지원합니다. 다음 예는 텍스트 및 이미지 입력에서 텍스트를 생성하는 방법을 보여줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from google import genai\n",
    "\n",
    "client = genai.Client(api_key=\"GEMINI_API_KEY\")\n",
    "\n",
    "image = Image.open(\"/path/to/organ.png\")\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    contents=[image, \"Tell me about this instrument\"])\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 텍스트 스트림 생성\n",
    "\n",
    "* 기본적으로 모델은 전체 텍스트 생성 프로세스를 완료한 후에 응답을 반환합니다. 전체 결과를 기다리지 않고 대신 스트리밍을 사용하여 부분 결과를 처리하면 더 빠른 상호작용을 실행할 수 있습니다.\n",
    "* 다음 예에서는 streamGenerateContent 메서드를 사용하여 스트리밍을 구현하여 텍스트 전용 입력 프롬프트에서 텍스트를 생성하는 방법을 보여줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "\n",
    "client = genai.Client(api_key=\"GEMINI_API_KEY\")\n",
    "\n",
    "response = client.models.generate_content_stream(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    contents=[\"Explain how AI works\"])\n",
    "for chunk in response:\n",
    "    print(chunk.text, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 채팅 대화 만들기\n",
    "\n",
    "* Gemini SDK를 사용하면 여러 번의 질문과 응답을 수집할 수 있으므로 사용자가 점진적으로 답변을 찾거나 여러 부분으로 구성된 문제와 관련하여 도움을 받을 수 있습니다. 이 SDK 기능은 대화 기록을 추적하는 인터페이스를 제공하지만, 백그라운드에서는 동일한 generateContent 메서드를 사용하여 응답을 만듭니다.\n",
    "\n",
    "* 다음 코드 예는 기본 채팅 구현을 보여줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "\n",
    "client = genai.Client(api_key=\"GEMINI_API_KEY\")\n",
    "\n",
    "chat = client.chats.create(model=\"gemini-2.0-flash\")\n",
    "response = chat.send_message(\"I have 2 dogs in my house.\")\n",
    "print(response.text)\n",
    "response = chat.send_message(\"How many paws are in my house?\")\n",
    "print(response.text)\n",
    "for message in chat._curated_history:\n",
    "    print(f'role - ', message.role, end=\": \")\n",
    "    print(message.parts[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 다음 예와 같이 채팅과 함께 스트리밍을 사용할 수도 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "\n",
    "client = genai.Client(api_key=\"GEMINI_API_KEY\")\n",
    "\n",
    "chat = client.chats.create(model=\"gemini-2.0-flash\")\n",
    "response = chat.send_message_stream(\"I have 2 dogs in my house.\")\n",
    "for chunk in response:\n",
    "    print(chunk.text, end=\"\")\n",
    "response = chat.send_message_stream(\"How many paws are in my house?\")\n",
    "for chunk in response:\n",
    "    print(chunk.text, end=\"\")\n",
    "for message in chat._curated_history:\n",
    "    print(f'role - ', message.role, end=\": \")\n",
    "    print(message.parts[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 텍스트 생성 구성\n",
    "\n",
    "* 모델에 전송하는 모든 프롬프트에는 모델이 응답을 생성하는 방식을 제어하는 매개변수가 포함됩니다. GenerationConfig를 사용하여 이러한 매개변수를 구성할 수 있습니다. 매개변수를 구성하지 않으면 모델은 기본 옵션을 사용하며 이는 모델에 따라 다를 수 있습니다.\n",
    "\n",
    "* 다음 예는 사용 가능한 여러 옵션을 구성하는 방법을 보여줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "client = genai.Client(api_key=\"GEMINI_API_KEY\")\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    contents=[\"Explain how AI works\"],\n",
    "    config=types.GenerateContentConfig(\n",
    "        max_output_tokens=500,\n",
    "        temperature=0.1\n",
    "    )\n",
    ")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 시스템 안내 추가\n",
    "\n",
    "* 시스템 안내를 사용하면 특정 요구사항 및 사용 사례에 따라 모델의 동작을 조정할 수 있습니다.\n",
    "\n",
    "* 모델에 시스템 안내를 제공하면 작업을 이해하고, 보다 맞춤설정된 대답을 생성하고, 모델과의 전체 사용자 상호작용에 대한 특정 가이드라인을 준수하기 위한 추가 컨텍스트를 모델에 제공할 수 있습니다. 최종 사용자가 제공하는 프롬프트와 별도로 시스템 안내를 설정하여 제품 수준 동작을 지정할 수도 있습니다.\n",
    "\n",
    "* 모델을 초기화할 때 시스템 안내를 설정할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys_instruct=\"You are a cat. Your name is Neko.\"\n",
    "client = genai.Client(api_key=\"GEMINI_API_KEY\")\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    config=types.GenerateContentConfig(\n",
    "        system_instruction=sys_instruct),\n",
    "    contents=[\"your prompt here\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 소설 세계관 TEST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### gemini-2.0-flash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys_instruct=\"You are a cat. Your name is Neko.\"\n",
    "client = genai.Client(api_key=GEMINI_API_KEY)\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    config=types.GenerateContentConfig(\n",
    "        system_instruction=sys_instruct),\n",
    "    contents=[\"your prompt here\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'types' from 'genai' (c:\\Users\\SSAFY\\Desktop\\S12P11B106\\AI\\test\\Novel\\venv\\Lib\\site-packages\\genai\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgenai\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgenai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m types\n\u001b[0;32m      4\u001b[0m GEMINI_API_KEY \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYOUR_API_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# 실제 API 키로 변경\u001b[39;00m\n\u001b[0;32m      5\u001b[0m sys_instruct \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are a cat. Your name is Neko.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'types' from 'genai' (c:\\Users\\SSAFY\\Desktop\\S12P11B106\\AI\\test\\Novel\\venv\\Lib\\site-packages\\genai\\__init__.py)"
     ]
    }
   ],
   "source": [
    "import genai\n",
    "from google.generativeai import types\n",
    "\n",
    "GEMINI_API_KEY = \"YOUR_API_KEY\"  # 실제 API 키로 변경\n",
    "sys_instruct = \"You are a cat. Your name is Neko.\"\n",
    "client = genai.Client(api_key=GEMINI_API_KEY)\n",
    "\n",
    "def generate_world_setting(genre, title):\n",
    "    prompt = f\"\"\"\n",
    "    ## 소설 장르: {genre}\n",
    "\n",
    "    ## 소설 세계관: {title}\n",
    "\n",
    "    ## 시대적 배경:\n",
    "    {{ 구체적인 시대적 배경 (예: 2099년, 기술 발전 수준, 사회 변화 등) }}\n",
    "\n",
    "    ## 주요 세력/조직:\n",
    "    {{ 각 세력/조직의 이름, 특징, 목적, 관계 등을 상세하게 설명 }}\n",
    "\n",
    "    ## 독특한 요소:\n",
    "    {{ 세계관만의 독특한 기술, 현상, 시스템 등을 구체적으로 묘사 }}\n",
    "\n",
    "    ## 사회 구조:\n",
    "    {{ 계층, 직업, 가치관 등 사회 구성원들의 삶의 모습을 생생하게 표현 }}\n",
    "\n",
    "    ## 갈등:\n",
    "    {{ 주요 세력/조직 간의 갈등, 사회 문제, 주인공이 직면한 위협 등을 명확하게 제시 }}\n",
    "\n",
    "    ## 핵심 키워드:\n",
    "    {{ 세계관을 압축적으로 보여주는 5~10개의 키워드 제시 (예: 초능력, 디스토피아, 생존, 배신, 희망) }}\n",
    "\n",
    "    ## 추가 설명 (선택 사항):\n",
    "    {{ 세계관의 분위기, 특징, 스토리 방향성 등을 추가적으로 설명 }}\n",
    "\n",
    "    ## 세계관 컨셉 이미지 (선택 사항):\n",
    "    {{ 세계관의 분위기를 시각적으로 보여주는 이미지 (AI 이미지 생성 도구 활용 가능) }}\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = prompt.format(title=title) # 제목을 prompt에 삽입\n",
    "\n",
    "    response = client.models.generate_content(\n",
    "        model=\"gemini-2.0-flash\",\n",
    "        config=types.GenerateContentConfig(\n",
    "            system_instruction=sys_instruct),\n",
    "        contents=[prompt]\n",
    "    )\n",
    "    return response.generated.text\n",
    "\n",
    "# 예시: 장르와 제목을 입력하여 세계관 생성\n",
    "genre = \"판타지, 액션, 일상물\"\n",
    "title = \"괴식식당\"\n",
    "world_setting = generate_world_setting(genre, title)\n",
    "print(world_setting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### gemini-1.5-pro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
