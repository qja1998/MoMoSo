# WebRTC를 활용한 음성

## 이미 사용중인 마이크를 backend에서 어떻게 사용할 것인가?

### 1. MediaRecorder를 이용해 Blob(또는 Binary Data)으로 전송
가장 간단한 방법으로 _MediaRecorder_ API를 사용하여 로컬 스트림으로부터 일정 간격(또는 일정 기간)으로 Blob 데이터를 생성하고, 이를 WebSocket이나 HTTP 업로드 방식 등으로 백엔드에 전송한다.

#### 개념흐름
1. Navigator.mediaDevices.getUUserMedia()로 획득한 로컬 스트림을 이용해 MediaRecorder 생성
2. MediaRecorder가 주기적으로 (예:500ms 간격) Blob 형태의 음성 데이터를 생성
3. 생성된 Blob을 WebSocket을 통해 전송 (또는 REST API로 업로드) 

#### 주의점
WebRTC 연결과는 별도로 추가 전송을 하는 것이므로, 사용자의 네트워크 상황에 따라 병목이 생길 수 있습니다. 특히 오디오/비디오를 동시에 백엔드와 P2P로 전송하면 트래픽이 증가할 수 있으니 상황에 맞게 설계해야한다.

---

### 2. SFU/MCU 같은 미디어 서버를 경유
두 번째 방법은 WebRTC 미디어 서버(예: Janus, Kurento, MediaSoup)를 사용하여 아예 서버도 WebRTC 파이프라인에 참여하게 하는 것입니다.

이 방식을 사용하면,

서버가 중앙 허브가 되어 다자간 화상/음성 통화를 효율적으로 중계하고,
서버 측에서 모든 참여자의 오디오/비디오 스트림을 실시간으로 받아서 녹화나 스트리밍, 분석(AI 음성인식 등) 등을 수행할 수 있습니다.
다만 이 경우에는 단순히 프론트엔드 코드만으로는 해결이 안 되고, 서버 쪽에 SFU/MCU를 구성해야 합니다.

라이브 스트리밍, 다자간 통화, 음성 인식 등 실시간성이 중요한 경우 이 방법이 좀 더 적합

하지만 초기 설정/구성이 복잡할 수 있음

---

### 3. RecordRTC.js
검색을 통해 알게된 라이브러리. 이 패키지를 사용하면 간편하게 WAV파일로 변환된 오디오 데이터를 얻을 수 있다.

MediaRecorder API의 경우 파일 형식이 webm만을 지원하기 때문에 STT와 파일 형식이 맞지 않는 문제

RecordRTC의 경우 WAV 파일로 전송하기에 우리 프로젝트에 더 맞다 생각되어 활용



## 결론
단순히 “마이크 음성을 별도로 백엔드에 저장/처리” 하려면, 위 1번 방식(프론트엔드 MediaRecorder)이 빠르게 적용 가능
실시간 다자간 통화 + 서버 저장/처리를 모두 원한다면, 2번처럼 미디어 서버(SFU/MCU) 아키텍처를 고려해보는 것이 좋습니다.

-> 1번 방법을 적용하던 중 더 좋은 3번(RecordRTC)를 찾아 3번 방법을 활용용